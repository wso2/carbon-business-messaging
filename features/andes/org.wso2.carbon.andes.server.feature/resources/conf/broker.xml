<?xml version="1.0" encoding="ISO-8859-1"?>
<!--
  ~ Copyright (c) 2015, WSO2 Inc. (http://www.wso2.org) All Rights Reserved.
  ~
  ~ WSO2 Inc. licenses this file to you under the Apache License,
  ~ Version 2.0 (the "License"); you may not use this file except
  ~ in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing,
  ~ software distributed under the License is distributed on an
  ~ "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  ~ KIND, either express or implied. See the License for the
  ~ specific language governing permissions and limitations
  ~ under the License.
  -->

<!-- This is the root configuration file of WSO2 Message Broker (MB). Links to configurations of 
associated libraries are also specified here. 

[Note for developers] - If you intend to rename or modify a property name, remember to update 
relevant, org.wso2.andes.configuration.enums.AndesConfiguration, enum value using the Xpath 
expression of the property. -->
<broker>

    <!--Paths of externally organized configurations specific to Andes component (Qpid configurations
    are referred by Qpid component separately. (MB_HOME/repository/conf/advanced/qpid-config.xml)-->
    <links>
    </links>

    <coordination>
        <!-- You can override the cluster node identifier of this MB node using the nodeID. 
        If it is left as "default", the default node ID will be generated for it. (Using IP + UUID).
        The node ID of each member should ALWAYS be unique.-->
        <nodeID>default</nodeID>

        <!-- Thrift is used to maintain and sync slot (message groups) ranges between MB nodes. -->
        <thriftServerHost>localhost</thriftServerHost>
        <thriftServerPort>7611</thriftServerPort>
        <!--Thrift server reconnect timeout. Value specified in SECONDS-->
        <thriftServerReconnectTimeout>5</thriftServerReconnectTimeout>
    </coordination>

    <!-- You can enable/disable specific messaging transports in this section. By default all 
    transports are enabled. This section also allows you to customize the messaging flows used 
    within WSO2 MB. NOT performance related, but logic related. -->
    <transports>
        <!-- In a clustered setup this should be updated with the IP address of this node
        Setting the value to 127.0.0.1 in a clustered setup is wrong. Please note that this is 
        the address exposed by the server. NOT the hostname inferred from carbon.xml -->
        <bindAddress>127.0.0.1</bindAddress>

        <amqp enabled="true">
            <!-- most of the AMQP configurations reside in qpid-config.xml since we inherit the Qpid
            messaging model during AMQP.-->
            <port>5672</port>
            <sslPort>8672</sslPort>
            <maximumRedeliveryAttempts>10</maximumRedeliveryAttempts>
            <allowSharedTopicSubscriptions>false</allowSharedTopicSubscriptions>
        </amqp>
        <mqtt enabled="true">
            <port>1883</port>
            <!-- put proper default SSL port -->
            <sslPort>8883</sslPort>
            <!-- These two properties are temporary. Ideally, MQTT should use carbon users. -->

            <!--Ring buffer size of MQTT inbound event disruptor. Default is set to 32768 (1024 * 32)
            Having a large ring buffer will have a increase memory usage and will improve performance
            and vise versa -->
            <inboundBufferSize>32768</inboundBufferSize>

            <!--Ring buffer size of MQTT delivery event disruptor. Default is set to 32768 (1024 * 32)
            Having a large ring buffer will have a increase memory usage and will improve performance
            and vise versa -->
            <deliveryBufferSize>32768</deliveryBufferSize>
            

            <security>
                   <!--
                       Instructs the MQTT server whether clients should always send credentials
                       when establishing a connection.
                       Possible values:
                        OPTIONAL: This is the default value. MQTT clients may or may not send 
                                  credentials. If a client sends credentials server will 
                                  validates it. 
                                  If client doesn't send credentials then server will not 
                                  authenticate, but allows client to establish the connection. 
                                  This behavior adheres to MQTT 3.1 specification.
                        REQUIRED: Clients should always provide credentials when connecting. 
                                  If client doesn't send credentials or they are invalid 
                                  server rejects the connection.
                   -->
                   <authentication>OPTIONAL</authentication>
                  
                   <!--Class name of the authenticator to use. class should 
                       inherit from org.dna.mqtt.moquette.server.IAuthenticator
                       Note: default implementation authenticates against carbon user store
                       based on supplied username/password
                   --> 
                   <authenticator>org.wso2.carbon.andes.authentication.andes.CarbonBasedMQTTAuthenticator</authenticator>
            </security>

        </mqtt>

    </transports>

    <!-- Depending on the database type selected in master-datasources.xml, you must enable the
    relevant Data access classes here. Currently supported stores are RDBMS(any RDBMS store) and
    Cassandra(CQL, Hector). These stores are accessed for two purposes.
    1. For message persistence ("messageStore")
    2. To persist and access other information relevant to messaging protocols.("contextStore").-->

    <!-- By default WSO2 MB runs with H2 persistent store. If you plan to use a different
    store, point to the relevant dataSource or uncomment the database appropriately.

    RDBMS
    =====
    If you are running an RDBMS you can use the existing RDBMS implementation of stores
    by pointing to the correct data source by updating the property "dataSource".

    Data source entry should be present in
    <MB_HOME>/repository/conf/datasources/master-datasources.xml.

    Cassandra
    =========
    For Cassandra depending on the driver (CQL or Hector) you use to connect to data store
    uncomment the relevant entry and COMMENT out the RDBMS entry.

    Update the <MB_HOME>/repository/conf/datasources/master-datasources.xml with Cassandra
    data source and update "dataSource" property for stores here.
    -->
    <persistence>

        <!-- RDBMS MB Store Configuration -->

        <messageStore class="org.wso2.andes.store.rdbms.RDBMSMessageStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="storeUnavailableSQLStateClasses">08</property>
            <property name="integrityViolationSQLStateClasses">23,27,44</property>
            <property name="dataErrorSQLStateClasses">21,22</property>
        </messageStore>

        <contextStore class="org.wso2.andes.store.rdbms.RDBMSAndesContextStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="storeUnavailableSQLStateClasses">08</property>
            <property name="integrityViolationSQLStateClasses">23,27,44</property>
            <property name="dataErrorSQLStateClasses">21,22</property>
        </contextStore>


        <!-- H2 Based In-Memory Store Configuration -->
<!--
        <messageStore class="org.wso2.andes.store.rdbms.h2.H2MemMessageStoreImpl">
        </messageStore>

        <contextStore class="org.wso2.andes.store.rdbms.h2.H2MemAndesContextStoreImpl">
        </contextStore>

-->

        <!-- External Cassandra Store Configuration -->

        <!-- NOTE: Update the master-datasources.xml file to connect to Cassandra data source
             READ the documentation to set advanced Cassandra tuning parameters.

            Advanced Tuning Parameters.

            gcGraceSeconds:
            Specifies the time to wait before garbage collecting tombstones (deletion markers).
            Defaults to 864000, or 10 days, which allows a great deal of time for consistency
            to be achieved prior to deletion. In many deployments this interval can be reduced,
            and in a single-node cluster it can be safely set to zero

            Replication strategy class:
            Strategy to determine the physical location of nodes to replication and their proximity
            to each other

            Replication factor:
            replication is the process of storing copies of data on multiple nodes to ensure
            reliability and fault tolerance. This value specify how many copies of same data should
            persisted.

            Read consistency level:
            Specifies how many replicas must respond to a read request before returning data
            Valid values are 'ONE','ALL','EACH_QUORUM','QUORUM','ONE','TWO','THREE','ANY'

            Write consistency level:
            Determines the number of replicas on which the write must succeed before returning an
            acknowledgement Valid values are
            'ONE','ALL','EACH_QUORUM','QUORUM','ONE','TWO','THREE','ANY' -->

        <!--CQL Based MB stores-->
<!--
        <messageStore class="org.wso2.andes.store.cassandra.CQLBasedMessageStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="keyspace">MB_KEYSPACE</property>
            <property name="gcGraceSeconds">864000</property>
            <property name="strategyClass">org.apache.cassandra.locator.SimpleStrategy</property>
            <property name="replicationFactor">1</property>
            <property name="readConsistencyLevel">ONE</property>
            <property name="writeConsistencyLevel">ONE</property>
        </messageStore>

        <contextStore class="org.wso2.andes.store.cassandra.CQLBasedAndesContextStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="keyspace">MB_KEYSPACE</property>
            <property name="strategyClass">org.apache.cassandra.locator.SimpleStrategy</property>
            <property name="replicationFactor">1</property>
            <property name="readConsistencyLevel">ONE</property>
            <property name="writeConsistencyLevel">ONE</property>
        </contextStore>
-->

        <!--Hector based MB stores-->
<!--
        <messageStore class="org.wso2.andes.store.cassandra.HectorBasedMessageStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="keyspace">MB_KEYSPACE</property>
            <property name="gcGraceSeconds">864000</property>
            <property name="strategyClass">org.apache.cassandra.locator.SimpleStrategy</property>
            <property name="replicationFactor">1</property>
            <property name="readConsistencyLevel">ONE</property>
            <property name="writeConsistencyLevel">ONE</property>
        </messageStore>

        <contextStore class="org.wso2.andes.store.cassandra.HectorBasedAndesContextStoreImpl">
            <property name="dataSource">WSO2MBStoreDB</property>
            <property name="keyspace">MB_KEYSPACE</property>
            <property name="gcGraceSeconds">864000</property>
            <property name="strategyClass">org.apache.cassandra.locator.SimpleStrategy</property>
            <property name="replicationFactor">1</property>
            <property name="readConsistencyLevel">ONE</property>
            <property name="writeConsistencyLevel">ONE</property>
        </contextStore>
-->

        <!-- This class decides how unique IDs are generated for the MB node. This id generator is
        expected to be thread safe and a implementation of interface
        org.wso2.andes.server.cluster.coordination.MessageIdGenerator

        NOTE: This is NOT used in MB to generate message IDs. -->
        <idGenerator>org.wso2.andes.server.cluster.coordination.TimeStampBasedMessageIdGenerator</idGenerator>

        <!-- This is the Task interval (in SECONDS) to check whether communication 
        is healthy between message store (/Database) and this server instance. -->
        <storeHealthCheckInterval>10</storeHealthCheckInterval>
    </persistence>

    <!-- Alter the flow that is triggered during a node fail -->
    <failoverBehaviour>

    </failoverBehaviour>

    <!--Publisher transaction related configurations.-->
    <transaction>

        <!--Number of connections reserved at a given time for transactional DB tasks.
        Transaction will hold on to a DB connection until a transaction is committed,
        rolled back or closed.-->
        <dbConnectionPoolSize>10</dbConnectionPoolSize>

        <!--Maximum batch size (Messages) for a transaction. Exceeding this limit will result
        in a failure in the subsequent commit request. Default is set to 10MB. Limit is
        calculated considering the payload of messages-->
        <maxBatchSizeInBytes>10000000</maxBatchSizeInBytes>
    </transaction>

    <!-- This section allows you to tweak memory and processor allocations used by WSO2 MB.
    Broken down by critical processes so you have a clear view of which parameters to change in
    different scenarios.  -->
    <performanceTuning>

        <slots>
            <!--maximum time interval where slot can be retain in memory before updating to the
            cluster, in milliseconds -->
            <slotRetainTimeInMemory>1000</slotRetainTimeInMemory>

            <!--rough estimate for size of a slot-->
            <windowSize>1000</windowSize>

            <!-- Published message information is sent to slot coordinator by the node when it
            either reaches the slot window size or the window creation timeout. This configures
            the timeout for slot window creation task.

            In a slow message publishing scenario, this is the delay for each message for delivery.
            For instance if we publish one message per minute then each message will have to wait
            till this timeout before the messages are submitted to the slot coordinator. Note that
            Messages are delivered only after the slot coordinator is informed -->
            <windowCreationTimeout>3000</windowCreationTimeout>

            <!--Number of SlotDeliveryWorker threads that should be started-->
            <workerThreadCount>5</workerThreadCount>

        </slots>

        <delivery>
            <!-- Maximum number of undelivered messages that can have in memory. Increasing this
            value increase the possibility of out of memory scenario but performance will be
            improved -->
            <maxNumberOfReadButUndeliveredMessages>1000</maxNumberOfReadButUndeliveredMessages>

            <!-- This is the ring buffer size of the delivery disruptor. This value should be a
            power of 2 (E.g. 1024, 2048, 4096). Use a small ring size if you want to reduce the
            memory usage. -->
            <ringBufferSize>4096</ringBufferSize>

            <!--Number of parallel readers used to used to read content from message store.
            Increasing this value will speed-up the message sending mechanism. But the load
            on the data store will increase. -->
            <parallelContentReaders>5</parallelContentReaders>

            <!-- Number of parallel delivery handlers used to send messages to subscribers.
            Increasing this value will speed-up the message sending mechanism. But the system load
            will increase. -->
            <parallelDeliveryHandlers>5</parallelDeliveryHandlers>

            <!-- The size of the batch represents, at a given time the number of messages that could 
            be retrieved from the database. -->
            <contentReadBatchSize>65000</contentReadBatchSize>
        </delivery>

        <ackHandling>
            <!--Number of message acknowledgement handlers to process acknowledgements concurrently.
            These acknowledgement handlers will batch and process acknowledgements.  -->
            <ackHandlerCount>1</ackHandlerCount>

            <!--Maximum batch size of the acknowledgement handler. Andes process acknowledgements in
            batches using Disruptor Increasing the batch size reduces the number of calls made to
            database by MB. Depending on the database optimal batch size this value should be set.
            Batches will be of the maximum batch size mostly in high throughput scenarios.
            Underlying implementation use Disruptor for batching hence will batch message at a
            lesser value than this in low throughput scenarios -->
            <ackHandlerBatchSize>100</ackHandlerBatchSize>

            <!-- Message delivery from server to the client will be paused temporarily if number of
            delivered but unacknowledged message count reaches this size. Should be set considering
            message consume rate. This is to avoid overwhelming slow subscribers. -->
            <maxUnackedMessages>1000</maxUnackedMessages>
        </ackHandling>

        <contentHandling>

            <!-- Within Andes there are content chunk handlers which convert incoming large content
            chunks into max content chunk size allowed by Andes core. These handlers run in parallel
            converting large content chunks to smaller chunks.

            If the protocol specific content chunk size is different from the max chunk size allowed
            by Andes core and there are significant number of large messages published, then having
            multiple handlers will increase performance. -->
            <contentChunkHandlerCount>3</contentChunkHandlerCount>

            <!-- Andes core will store message content chunks according to this chunk size. Different
            database will have limits and performance gains by tuning this parameter.

            For instance in MySQL the maximum table column size for content is less than 65534, which
            is the default chunk size of AMQP. By changing this parameter to a lesser value we can
            store large content chunks converted to smaller content chunks within the DB with this
            parameter. -->
            <maxContentChunkSize>65500</maxContentChunkSize>
        </contentHandling>

        <inboundEvents>
            <!--Number of parallel writers used to write content to message store. Increasing this
            value will speed-up the message receiving mechanism. But the load on the data store will
            increase.-->
            <parallelMessageWriters>1</parallelMessageWriters>

            <!--Size of the Disruptor ring buffer for inbound event handling. For publishing at
            higher rates increasing the buffer size may give some advantage on keeping messages in
            memory and write.

            NOTE: Buffer size should be a value of power of two -->
            <bufferSize>65536</bufferSize>

            <!--Maximum batch size of the batch write operation for inbound messages. MB internals
            use Disruptor to batch events. Hence this batch size is set to avoid database requests
            with high load (with big batch sizes) to write messages. This need to be configured in
            high throughput messaging scenarios to regulate the hit on database from MB -->
            <messageWriterBatchSize>70</messageWriterBatchSize>

            <!--Timeout for waiting for a queue purge event to end to get the purged count. Doesn't
            affect actual purging. If purge takes time, increasing the value will improve the
            possibility of retrieving the correct purged count. Having a lower value doesn't stop
            purge event. Getting the purged count is affected by this -->
            <purgedCountTimeout>180</purgedCountTimeout>

            <!--Number of parallel writers used to write content to message store for transaction
            based publishing. Increasing this value will speedup commit duration for a transaction.
            But the load on the data store will increase.-->
            <transactionMessageWriters>1</transactionMessageWriters>
        </inboundEvents>

        <failover>
            <!-- Virtual host sync interval seconds in for the Virtual host syncing Task which will
            sync the Virtual host details across the cluster -->
            <vHostSyncTaskInterval>3600</vHostSyncTaskInterval>
        </failover>

        <messageExpiration>
            <checkInterval>10000</checkInterval>
            <messageBatchSize>1000</messageBatchSize>
        </messageExpiration>

        <messageCounter>
            <!-- Message counter tasks delay between the termination of one execution and the
            commencement of the next in seconds -->
            <counterTaskInterval>5</counterTaskInterval>

            <!-- Message count is updated in batches. Once the count exceed the batch size message
            count update is moved to message count update task. -->
            <countUpdateBatchSize>100</countUpdateBatchSize>
        </messageCounter>

        <!-- Code specific parameters to ensure messages get deleted as fast as possible without
        disturbing other processes.-->
        <messageDeletion>
            <!-- This is the Task interval (SECONDS) for the content removal task which will remove
            the actual message content from the store in the background. If the message rate is very
            high, users can set this to a lower value to minimise the delete requests per task. -->
            <contentRemovalTaskInterval>3</contentRemovalTaskInterval>
        </messageDeletion>

        <!--
            SIMPLE - Default Selector Mechanism
            BITMAPS - BitMaps
            When using the subscriptions and topics in large quantity, BitMaps are faster than
            the existing ones
         -->
        <topicMatching>SIMPLE</topicMatching>

    </performanceTuning>

    <!-- This section is about how you want to view messaging statistics from the admin console and
    how you plan to interact with it. -->
    <managementConsole>
        <!--Maximum number of messages to be fetched using Andes message browser when browsing
        queues -->
        <messageBatchSizeForBrowserSubscriptions>100</messageBatchSizeForBrowserSubscriptions>

        <!-- This property defines the maximum message content length that can be displayed at the
        management console when browsing queues. If the message length exceeds the value, a
        truncated content will be displayed with a statement "message content too large to display."
        at the end. default value is 100000 (can roughly display a 100KB message.)
        * NOTE : Increasing this value could cause delays when loading the message content page.-->
        <maximumMessageDisplayLength>100000</maximumMessageDisplayLength>

    </managementConsole>

    <!-- Memory and resource exhaustion is something we should prevent and recover from.
    This section allows you to specify the threshold at which to reduce/stop frequently intensive
    operations within MB temporarily. -->
    <flowControl>
        <!-- This is the global buffer limits which enable/disable the flow control globally -->
        <global>
            <lowLimit>800</lowLimit>
            <highLimit>8000</highLimit>
        </global>

        <!-- This is the channel specific buffer limits which enable/disable the flow control
        locally -->
        <bufferBased>
            <lowLimit>100</lowLimit>
            <highLimit>1000</highLimit>
        </bufferBased>

        <memoryBased>
            <memoryCheckInterval>20000</memoryCheckInterval>
            <globalMemoryThresholdRatio>1.0</globalMemoryThresholdRatio>
            <globalMemoryRecoveryThresholdRatio>1.0</globalMemoryRecoveryThresholdRatio>
        </memoryBased>
        <connectionBased>
            <perConnectionMessageThreshold>1000</perConnectionMessageThreshold>
        </connectionBased>
    </flowControl>

    <slotManagement>
        <!--Set slot storage mode (RDBMS/HazelCast)-->
        <storage>HazelCast</storage>
    </slotManagement>


    <!--
    Message broker keeps track of all messages it has received as groups. These groups are termed
    'Slots' (To know more information about Slots and message broker install please refer to online wiki).
    Size of a slot is loosely determined by the configuration <windowSize> (and the number of
    parallel publishers for specific topic/queue). Message broker cluster (or in single node) keeps
    track of slots which constitutes for a large part of operating state before the cluster went down.

    When first message broker node of the cluster starts up, it will read the database to recreate
    the internal state to previous state. In a deployment where Cassandra is the message storage, this
    broker node has to avoid (please refer to Cassandra documentation for more information) tombstones
    when reading messages. Each message stored in message store has a unique internal ID. This id is
    based on time on which the message was published. To minimize the effect of tombstones, MB will use
    'range queries' where ranges are defined using these messages ID. During this start up, message broker
    will calculate a starting message ID based on date given below. This significantly improves the (warm)
    start up time. So If you are going to warm start message broker, set this value closer to the date
    (but before) which oldest message was received by this broker cluster. For example: date of cluster
    set setup, 1st of this month/year.
     -->
    <recovery>
        <!-- NOTE: please define date and time as yyyy-MM-dd HH:mm:ss -->
        <startRecoveryFrom>2015-05-27 00:00:00</startRecoveryFrom>
        <!--
        We will reading following number of message ids in a particular database call. Please note that
        increasing value of below property may cause TombstoneOverwhelmingException in Cassandra as
        message store
         -->
        <recoveryWindowSize>100000</recoveryWindowSize>
        <!--
        There could be multiple storage queues worked before entire cluster (or single node) went down.
        We need to recover all remaining messages of each storage queue when first node startup and we can
        read remaining message concurrently of each storage queue. Default value to set here to 5. You can
        increase this value based on number of storage queues exist. Please note that increasing value may
        cause to heavy load in Cassandra due to multiple read calls. Please use optimal value based on
        number of storage queues to speed up warm startup.
        -->
        <concurrentStorageQueueReads>5</concurrentStorageQueueReads>
    </recovery>

</broker>
